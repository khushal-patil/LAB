Excellent â€” this is your **Machine Learning Practical 2**:
**Email Spam Classification using KNN and SVM.**
Youâ€™ve provided the `.ipynb` (Jupyter Notebook) and the lab PDF. Iâ€™ll now give you a **step-by-step explanation of every command**, all relevant **formulas**, detailed **viva-style answers** (including your 4 theory questions), and examples that examiners often ask.

---

# ğŸ¯ Objective

To **classify emails as Spam (1)** or **Not Spam (0)** using two supervised learning methods:

1. **K-Nearest Neighbors (KNN)**
2. **Support Vector Machine (SVM)**

Youâ€™ll evaluate both models on metrics like **accuracy, precision, recall, and F1-score**.

---

# ğŸ§© 1ï¸âƒ£ Import Libraries â€” Why & What They Do

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
```

### Explanation

| Command                                                       | Meaning                                                                    |
| ------------------------------------------------------------- | -------------------------------------------------------------------------- |
| `pandas as pd`                                                | Handles tabular dataset (load/read CSV, DataFrame operations).             |
| `numpy as np`                                                 | Handles numerical computation and array operations.                        |
| `matplotlib.pyplot`, `seaborn`                                | Visualization (plots, heatmaps, etc.).                                     |
| `train_test_split`                                            | Splits dataset into training and testing subsets.                          |
| `TfidfVectorizer`                                             | Converts email text into numerical feature vectors using TF-IDF weighting. |
| `StandardScaler`                                              | Scales numerical features (important for KNN and SVM).                     |
| `KNeighborsClassifier`                                        | Implements the KNN algorithm for classification.                           |
| `SVC`                                                         | Support Vector Classifier â€” implementation of SVM.                         |
| `accuracy_score`, `confusion_matrix`, `classification_report` | Evaluation metrics.                                                        |

---

# ğŸ§© 2ï¸âƒ£ Load and Inspect Dataset

```python
df = pd.read_csv("emails.csv")
df.head()
df.info()
df.isnull().sum()
df['spam'].value_counts()
```

### Explanation

| Command                     | Purpose                                                       |
| --------------------------- | ------------------------------------------------------------- |
| `pd.read_csv()`             | Reads the dataset into a pandas DataFrame.                    |
| `df.head()`                 | Displays the first 5 rows â€” quick look at data columns.       |
| `df.info()`                 | Shows data types and missing values.                          |
| `df.isnull().sum()`         | Counts missing values per column.                             |
| `df['spam'].value_counts()` | Shows how many spam vs non-spam emails exist (class balance). |

âœ… *Usually, `spam` = 1 means Spam, `spam` = 0 means Not Spam.*

---

# ğŸ§© 3ï¸âƒ£ Text Preprocessing

```python
X = df['text']
y = df['spam']
```

* `X` â†’ Independent variable (email body text).
* `y` â†’ Target variable (0 or 1).

---

# ğŸ”¹ TF-IDF Vectorization

```python
vectorizer = TfidfVectorizer(stop_words='english', max_features=3000)
X_vec = vectorizer.fit_transform(X)
```

### Explanation

* **TF-IDF (Term Frequencyâ€“Inverse Document Frequency)**

  * Converts words into numeric weights based on how important each word is in an email relative to the entire dataset.

* **Formula:**
  [
  TF\text{-}IDF(t,d) = TF(t,d) \times \log\frac{N}{DF(t)}
  ]
  where

  * ( TF(t,d) ): term frequency of word *t* in document *d*,
  * ( DF(t) ): number of documents containing *t*,
  * ( N ): total number of documents.

* **Parameters:**

  * `stop_words='english'` removes common words like â€œandâ€, â€œisâ€, â€œtheâ€.
  * `max_features=3000` keeps top 3000 important words to reduce dimensionality.

---

# ğŸ§© 4ï¸âƒ£ Train-Test Split

```python
X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)
```

* 80% â†’ Training, 20% â†’ Testing.
* `random_state=42` ensures reproducible split.
* Model trains on `X_train, y_train` and evaluates on unseen `X_test, y_test`.

---

# ğŸ§© 5ï¸âƒ£ KNN Model â€” Training & Prediction

```python
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)
```

### Explanation

* **`n_neighbors=5`** â†’ considers 5 nearest neighbors for prediction.
* **Formula:**
  To predict label of test sample (x_q):
  [
  \hat{y}(x_q) = \text{mode of } {y_i : x_i \in K\text{ nearest neighbors of } x_q}
  ]

  * Distance metric usually **Euclidean Distance**:
    [
    d(x, x_i) = \sqrt{\sum_{j=1}^{n} (x_j - x_{ij})^2}
    ]
* The class with the most votes among k neighbors becomes the prediction.

---

# ğŸ§© 6ï¸âƒ£ Evaluate KNN

```python
print("KNN Accuracy:", accuracy_score(y_test, y_pred_knn))
print(confusion_matrix(y_test, y_pred_knn))
print(classification_report(y_test, y_pred_knn))
```

### Explanation

* **Accuracy:**
  [
  Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
  ]
* **Confusion Matrix:**

  | Actual / Predicted | Not Spam (0) | Spam (1) |
  | ------------------ | ------------ | -------- |
  | Not Spam (0)       | TN           | FP       |
  | Spam (1)           | FN           | TP       |
* **Classification Report:** prints Precision, Recall, and F1-Score:

  * **Precision:** ( \frac{TP}{TP + FP} )
  * **Recall:** ( \frac{TP}{TP + FN} )
  * **F1:** ( 2 \times \frac{Precision \times Recall}{Precision + Recall} )

---

# ğŸ§© 7ï¸âƒ£ Support Vector Machine (SVM)

```python
svm = SVC(kernel='linear')
svm.fit(X_train, y_train)
y_pred_svm = svm.predict(X_test)
```

### Explanation

* **SVC** = Support Vector Classifier.
* **kernel='linear'** means it tries to separate data using a linear decision boundary.
* **Formula (Linear SVM Decision Boundary):**
  [
  f(x) = w \cdot x + b
  ]
  SVM optimizes (w, b) to maximize **margin**, i.e., distance between separating hyperplane and closest data points (support vectors).

  Margin width (= \frac{2}{||w||})

---

# ğŸ§© 8ï¸âƒ£ Evaluate SVM

```python
print("SVM Accuracy:", accuracy_score(y_test, y_pred_svm))
print(confusion_matrix(y_test, y_pred_svm))
print(classification_report(y_test, y_pred_svm))
```

Same metrics as KNN â€” allows you to compare both.

Typically, **SVM outperforms KNN** on text data because:

* High-dimensional sparse data (TF-IDF vectors)
* SVM handles it efficiently.

---

# ğŸ§© 9ï¸âƒ£ Performance Comparison Example

| Model | Accuracy | Precision | Recall | F1   |
| ----- | -------- | --------- | ------ | ---- |
| KNN   | 0.93     | 0.91      | 0.89   | 0.90 |
| SVM   | 0.97     | 0.96      | 0.97   | 0.96 |

âœ… So SVM performs better overall for spam classification.

---

# ğŸ§® 10ï¸âƒ£ Visualization (Optional)

```python
sns.heatmap(confusion_matrix(y_test, y_pred_svm), annot=True, fmt='d', cmap='Blues')
plt.title("SVM Confusion Matrix")
plt.show()
```

* Displays confusion matrix as a heatmap.
* `annot=True` shows numbers in cells.

---

# ğŸ“ Theory & Viva Section

## 1ï¸âƒ£ Why should we not use the KNN algorithm for large datasets?

**Because it is computationally expensive:**

* **Training time:** O(1) (just stores data)
* **Prediction time:** O(n Ã— d) where n = #samples, d = #features
  â†’ Every new test point must compute distance to all training points.

So KNN is **slow for large datasets** because distance calculations scale linearly with dataset size.
Also, memory usage is high since the entire dataset must be stored.

**Example viva answer:**

> â€œKNN compares the test sample with every training sample to find nearest neighbors.
> For millions of emails, that becomes very slow, so KNN is inefficient for large datasets.â€

---

## 2ï¸âƒ£ Is Feature Scaling required for the KNN Algorithm? Explain with proper justification.

âœ… **Yes, absolutely required.**

Because KNN uses **distance-based similarity** (e.g., Euclidean distance).
If features are on different scales, large-scale features dominate.

**Example:**

* Feature1 = word count (0â€“1000)
* Feature2 = punctuation ratio (0â€“1)

Distance = âˆš((Î”F1)Â² + (Î”F2)Â²) â†’ Feature1 dominates.
Scaling (Standardization or Normalization) ensures all features contribute equally.

**Formula (Standardization):**
[
z = \frac{x - \mu}{\sigma}
]
Where:

* ( \mu ) = mean, ( \sigma ) = standard deviation.

---

## 3ï¸âƒ£ What do you mean by Hinge Loss?

Hinge Loss is used by **Support Vector Machines** to measure misclassification error.

**Formula:**
[
L(y, f(x)) = \max(0, 1 - y \cdot f(x))
]
Where:

* (y \in {-1, +1}) â†’ true label
* (f(x)) â†’ model output before sign

âœ… Intuition:

* If correct & confidently classified (margin â‰¥ 1): loss = 0
* If within margin or wrong side: positive loss (penalty).

**Example:**

| y  | f(x) | 1 - y*f(x) | Loss |
| -- | ---- | ---------- | ---- |
| +1 | 2    | -1         | 0    |
| +1 | 0.2  | 0.8        | 0.8  |
| -1 | 0.5  | 1.5        | 1.5  |

**Purpose:** Enforces correct classification with a safety margin.

---

## 4ï¸âƒ£ Whatâ€™s the â€œKernel Trickâ€ and how is it useful?

**Kernel Trick:** a mathematical technique in SVM that implicitly maps input data into a higher-dimensional space **without explicitly computing** the transformation.

**Formula:**
[
K(x_i, x_j) = \phi(x_i) \cdot \phi(x_j)
]
Where ( \phi(x) ) = transformation function.

**Common Kernels:**

| Kernel         | Formula                        | Purpose                             |
| -------------- | ------------------------------ | ----------------------------------- |
| Linear         | (x_i \cdot x_j)                | For linearly separable data         |
| Polynomial     | ((x_i \cdot x_j + c)^d)        | Captures non-linear relationships   |
| RBF (Gaussian) | ( \exp(-\gamma |x_i - x_j|^2)) | Most popular for complex boundaries |

âœ… **Why useful:**
Instead of manually mapping data into high dimensions (which is costly), kernel trick computes inner products directly â€” faster and efficient.

**Example viva line:**

> â€œKernel trick lets SVM handle non-linear data by using kernel functions like RBF to implicitly project inputs to higher dimensions.â€

---

# ğŸ“˜ Extra viva questions examiners often ask

| Question                              | Short Answer                                                                          |
| ------------------------------------- | ------------------------------------------------------------------------------------- |
| **Why SVM is good for text data?**    | Text â†’ high-dimensional â†’ SVM handles high-dimensional sparse features efficiently.   |
| **Difference between KNN and SVM?**   | KNN = lazy learner, instance-based; SVM = margin-based, generalizes better.           |
| **What is margin in SVM?**            | Distance between the separating hyperplane and nearest data points (support vectors). |
| **What happens if classes overlap?**  | SVM uses soft-margin (C parameter) to allow misclassifications.                       |
| **Whatâ€™s TF-IDF?**                    | Term importance measure: high when term frequent in a document but rare globally.     |
| **Why use accuracy + F1 both?**       | Accuracy fails for imbalanced data; F1 balances precision & recall.                   |
| **Why is SVM better for small data?** | Works well in high-dimensional but small-sample spaces; avoids overfitting.           |

---

# ğŸ¯ Summary â€” What to Present in Your Lab

* Show dataset loaded & cleaned.
* Show TF-IDF matrix shape (e.g., 5000 Ã— 3000).
* Print train/test split summary.
* Display confusion matrices for KNN & SVM.
* Compare metrics in a table: accuracy, precision, recall, F1.
* Write short conclusion: â€œSVM performed better due to its ability to separate high-dimensional data efficiently.â€

---

Would you like me to produce a **one-page PDF summary** (with formulas + diagrams of margin & kernel trick) so you can attach it to your ML practical record? Itâ€™s perfect for viva and printout submission.
